{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "lTetOo66Iko7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install openai-whisper\n",
        "# !pip install ffmpeg-python\n",
        "# !pip install transformers\n",
        "# !pip install yt_dlp\n",
        "# !pip install moviepy==1.0.3\n",
        "# !pip install gtts\n",
        "# !pip install pydub\n",
        "!pip install gradio\n",
        "# !pip install openai-whisper\n",
        "# !pip install google-generativeai\n",
        "# !pip install gTTS\n",
        "# !pip install pydub\n",
        "# !pip install moviepy\n",
        "# !pip install spleeter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9_YD47HIJwk",
        "outputId": "98c17260-ea4c-466a-ecf2-c6057a5bfac0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.23.3)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.8.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.24.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.4)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.1)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.1->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# importing dependencies"
      ],
      "metadata": {
        "id": "JDiaUc7uJiPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import whisper\n",
        "import google.generativeai as genai\n",
        "from gtts import gTTS\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "from moviepy.editor import VideoFileClip , AudioFileClip\n",
        "import torch\n",
        "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
        "from datetime import timedelta\n",
        "from gtts import gTTS\n",
        "from pydub import AudioSegment\n",
        "import re\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "_57XluYkPtJx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Audio from Video"
      ],
      "metadata": {
        "id": "zG5CdENIxF93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_audio(video_path):\n",
        "    video = VideoFileClip(video_path)\n",
        "    video.audio.write_audiofile(\"temp_audio.wav\")\n",
        "    print(\"Extracted Audio\")\n",
        "    return \"temp_audio.wav\"\n",
        "\n",
        "# print(extract_audio(\"/content/temp/test_video_2.mp4\"))"
      ],
      "metadata": {
        "id": "ZxTVw2YlRgoU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Vocals from audio"
      ],
      "metadata": {
        "id": "y8NAsRVOxicH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def isolate_vocals(audio_path):\n",
        "    os.system(f\"spleeter separate -p spleeter:2stems -o output {audio_path}\")\n",
        "    print(\"Extracted Vocals\")\n",
        "    return \"output/temp_audio/vocals.wav\"  # Path to isolated vocals\n",
        "\n",
        "# print(isolate_vocals(\"/content/temp_audio.wav\"))"
      ],
      "metadata": {
        "id": "ABYx6-WnTWIR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting text , translating it and creating subtitle ."
      ],
      "metadata": {
        "id": "-oMV1txpyBN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load models\n",
        "whisper_model = whisper.load_model(\"base\")\n",
        "translation_model_name = \"facebook/m2m100_418M\"\n",
        "tokenizer = M2M100Tokenizer.from_pretrained(translation_model_name)\n",
        "translator = M2M100ForConditionalGeneration.from_pretrained(translation_model_name).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def format_timestamp(seconds):\n",
        "    return str(timedelta(seconds=int(seconds)))\n",
        "\n",
        "def translate(text, target_lang):\n",
        "    tokenizer.src_lang = \"en\"\n",
        "    encoded = tokenizer(text, return_tensors=\"pt\").to(translator.device)\n",
        "    generated = translator.generate(**encoded, forced_bos_token_id=tokenizer.get_lang_id(target_lang))\n",
        "    return tokenizer.decode(generated[0], skip_special_tokens=True)\n",
        "\n",
        "def transcribe_and_translate(audio_path, target_lang=\"hi\", save_srt=True):\n",
        "    # print(\"🔍 Transcribing with timestamps...\")\n",
        "    result = whisper_model.transcribe(audio_path, verbose=True)\n",
        "\n",
        "    srt_output = \"\"\n",
        "    for i, segment in enumerate(result['segments']):\n",
        "        start = format_timestamp(segment['start'])\n",
        "        end = format_timestamp(segment['end'])\n",
        "        original_text = segment['text'].strip()\n",
        "        translated_text = translate(original_text, target_lang)\n",
        "\n",
        "        srt_output += f\"{i+1}\\n{start} --> {end}\\n{translated_text}\\n\\n\"\n",
        "\n",
        "    if save_srt:\n",
        "        with open(\"translated_subtitles.srt\", \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(srt_output)\n",
        "        # print(\"✅ Saved subtitles to translated_subtitles.srt\")\n",
        "    print(\"translated text\")\n",
        "    return \"translated_subtitles.srt\"\n",
        "\n",
        "# === Run it ===\n",
        "# audio_path = \"/content/temp_audio.wav\"\n",
        "# print(transcribe_and_translate(audio_path, target_lang=\"hi\"))\n"
      ],
      "metadata": {
        "id": "wlSdPyOFTYDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "from datetime import datetime\n",
        "import re\n",
        "from gtts import gTTS\n",
        "import os\n",
        "\n",
        "def time_to_ms(time_str):\n",
        "    \"\"\"Convert SRT time format to milliseconds\"\"\"\n",
        "    h, m, s = map(float, time_str.strip().replace(',', '.').split(':'))\n",
        "    return int((h * 3600 + m * 60 + s) * 1000)\n",
        "\n",
        "def sync_audio(srt_path, output_path=\"synced_translated_audio.mp3\", lang='hi', speed_factor=1.3):\n",
        "    \"\"\"\n",
        "    Generate synchronized audio from translated subtitles\n",
        "\n",
        "    Args:\n",
        "        srt_path (str): Path to SRT subtitle file\n",
        "        output_path (str): Output audio file path\n",
        "        lang (str): Language code for TTS (default: 'hi' for Hindi)\n",
        "        speed_factor (float): Audio speed multiplier (1.0 = normal)\n",
        "\n",
        "    Returns:\n",
        "        str: Path to generated audio file\n",
        "    \"\"\"\n",
        "    # Read SRT file\n",
        "    with open(srt_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        content = f.read()\n",
        "\n",
        "    blocks = re.split(r\"\\n\\s*\\n\", content.strip())\n",
        "    final_audio = AudioSegment.silent(duration=0)\n",
        "    current_time = 0  # in milliseconds\n",
        "\n",
        "    # Temporary directory for line audio files\n",
        "    os.makedirs(\"temp_tts\", exist_ok=True)\n",
        "\n",
        "    for i, block in enumerate(blocks):\n",
        "        lines = block.strip().split(\"\\n\")\n",
        "        if len(lines) < 3:\n",
        "            continue\n",
        "\n",
        "        # Parse subtitle block\n",
        "        timing = lines[1]\n",
        "        text = \" \".join(lines[2:])\n",
        "        start_time, end_time = timing.split(\"-->\")\n",
        "        start_ms = time_to_ms(start_time)\n",
        "        end_ms = time_to_ms(end_time)\n",
        "\n",
        "        print(f\"🔊 [{start_time.strip()}] {text}\")\n",
        "\n",
        "        # Add silence gap if needed\n",
        "        if start_ms > current_time:\n",
        "            silence = AudioSegment.silent(duration=start_ms - current_time)\n",
        "            final_audio += silence\n",
        "\n",
        "        # Generate TTS audio\n",
        "        temp_file = f\"temp_tts/line_{i+1}.mp3\"\n",
        "        try:\n",
        "            tts = gTTS(text=text, lang=lang)\n",
        "            tts.save(temp_file)\n",
        "\n",
        "            # Process audio segment\n",
        "            segment = AudioSegment.from_mp3(temp_file)\n",
        "            segment = segment.speedup(playback_speed=speed_factor)\n",
        "\n",
        "            # Trim to fit time slot\n",
        "            max_duration = end_ms - start_ms\n",
        "            if len(segment) > max_duration:\n",
        "                segment = segment[:max_duration]\n",
        "\n",
        "            final_audio += segment\n",
        "            current_time = start_ms + len(segment)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error processing block {i+1}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    # Export final audio\n",
        "    final_audio.export(output_path, format=\"mp3\")\n",
        "\n",
        "    # Cleanup temporary files\n",
        "    for f in os.listdir(\"temp_tts\"):\n",
        "        os.remove(os.path.join(\"temp_tts\", f))\n",
        "    os.rmdir(\"temp_tts\")\n",
        "\n",
        "    print(f\"✅ Successfully generated synchronized audio at: {output_path}\")\n",
        "    print(\"audio_synced.\")\n",
        "    return output_path\n",
        "\n",
        "# Example usage\n",
        "# audio_path = sync_audio(\n",
        "#     srt_path=\"translated_subtitles.srt\",\n",
        "#     output_path=\"final_audio.mp3\",\n",
        "#     lang='hi',\n",
        "#     speed_factor=1.25\n",
        "# )"
      ],
      "metadata": {
        "id": "bi88OlL3Tz6O"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_audio(vocals_path, original_audio_path):\n",
        "    background = AudioSegment.from_file(\"output/temp_audio/accompaniment.wav\")\n",
        "    voice = AudioSegment.from_file(vocals_path)\n",
        "    combined = background.overlay(voice)\n",
        "    combined.export(\"final_audio.wav\", format=\"wav\")\n",
        "    print(\"merged audio\")\n",
        "    return \"final_audio.wav\"\n",
        "\n",
        "# print(merge_audio(\"final_audio.mp3\", \"/content/temp_audio.wav\"))"
      ],
      "metadata": {
        "id": "ggXBRZgeUEwy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip, AudioFileClip\n",
        "import gradio as gr\n",
        "import os\n",
        "\n",
        "\n",
        "def process_video(video_path, target_langs):\n",
        "    \"\"\"\n",
        "    Process video and translate to multiple languages\n",
        "\n",
        "    Args:\n",
        "        video_path (str): Path to input video\n",
        "        target_langs (list): List of language codes (e.g., ['hi', 'ta', 'te'])\n",
        "\n",
        "    Returns:\n",
        "        dict: Paths to translated videos {lang: video_path}\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "\n",
        "    # Step 1: Extract and process original audio\n",
        "    audio_path = extract_audio(video_path)\n",
        "    vocals_path = isolate_vocals(audio_path)\n",
        "    bg_audio_path = f\"output/{os.path.splitext(os.path.basename(audio_path))[0]}/accompaniment.wav\"\n",
        "\n",
        "    for lang in target_langs:\n",
        "        print(f\"\\n🌐 Processing {lang} translation...\")\n",
        "\n",
        "        # Step 2: Transcribe and translate\n",
        "        srt_path = transcribe_and_translate(audio_path, target_lang=lang)\n",
        "\n",
        "        # Step 3: Generate synchronized TTS audio\n",
        "        synced_audio_path = sync_audio(srt_path, lang=lang)\n",
        "\n",
        "        # Step 4: Merge with background\n",
        "        final_audio_path = merge_audio(synced_audio_path, bg_audio_path)\n",
        "\n",
        "        # Step 5: Create translated video\n",
        "        output_path = f\"output_video_{lang}.mp4\"\n",
        "        video_clip = VideoFileClip(video_path)\n",
        "        final_clip = video_clip.set_audio(AudioFileClip(final_audio_path))\n",
        "        final_clip.write_videofile(output_path)\n",
        "\n",
        "        results[lang] = output_path\n",
        "        print(f\"✅ {lang.upper()} version saved to {output_path}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Gradio Interface with Multi-Language Support\n",
        "lang_choices = [\n",
        "    (\"Hindi\", \"hi\"),\n",
        "    (\"Tamil\", \"ta\"),\n",
        "    (\"Telugu\", \"te\"),\n",
        "    (\"Bengali\", \"bn\"),\n",
        "    (\"Marathi\", \"mr\"),\n",
        "    (\"Gujarati\", \"gu\"),\n",
        "    (\"Kannada\", \"kn\"),\n",
        "    (\"Malayalam\", \"ml\"),\n",
        "    (\"Punjabi\", \"pa\"),\n",
        "    (\"Odia\", \"or\"),\n",
        "    (\"Assamese\", \"as\"),\n",
        "    (\"Urdu\", \"ur\"),\n",
        "    (\"Sanskrit\", \"sa\")\n",
        "]\n",
        "\n",
        "def gradio_interface(video, language_checkboxes):\n",
        "    selected_langs = [code for (name, code) in lang_choices if name in language_checkboxes]\n",
        "    if not selected_langs:\n",
        "        return \"⚠️ Please select at least one language\"\n",
        "\n",
        "    results = process_video(video, selected_langs)\n",
        "    return list(results.values())\n",
        "\n",
        "# Create Gradio interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## 🌍 Multi-Language Video Translator\")\n",
        "\n",
        "    with gr.Row():\n",
        "        video_input = gr.Video(label=\"Input Video\")\n",
        "        output_gallery = gr.Gallery(label=\"Translated Videos\")\n",
        "\n",
        "    lang_checkboxes = gr.CheckboxGroup(\n",
        "        choices=[name for (name, code) in lang_choices],\n",
        "        label=\"Target Languages\",\n",
        "        value=[\"Hindi\"]\n",
        "    )\n",
        "\n",
        "    submit_btn = gr.Button(\"Translate\")\n",
        "    submit_btn.click(\n",
        "        fn=gradio_interface,\n",
        "        inputs=[video_input, lang_checkboxes],\n",
        "        outputs=output_gallery\n",
        "    )\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "pnOM_-9o606M",
        "outputId": "573489d5-e488-43e5-ec49-d8f43834bf3a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://d819dcc8115d26ebcc.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d819dcc8115d26ebcc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jc9dHbOw-5TW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}